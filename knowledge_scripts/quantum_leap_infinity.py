"""
‚ôæÔ∏è QUANTUM LEAP INFINITY - AUTONOMOUS KNOWLEDGE EXPANSION ENGINE
Target: 2,000,000+ Words

Este script n√£o possui t√≥picos hardcoded. Ele funciona como um AGENTE AUT√îNOMO:
1. Escolhe uma Macro-√Årea (ex: Nanotecnologia, Hist√≥ria Antiga, Astrof√≠sica)
2. Pede ao Gemini: "Gere 5 t√≥picos PhD ultra-espec√≠ficos e in√©ditos nesta √°rea"
3. Gera o conte√∫do para cada t√≥pico
4. Indexa na mem√≥ria
5. Repete indefinidamente at√© atingir a meta.

Isso garante diversidade infinita sem repeti√ß√£o.
"""

import os
import sys
import json
import random
import time
from datetime import datetime

# Setup paths
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from codex_ia.core.vector_store import CodexVectorStore
from codex_ia.core.llm_client import GeminiClient
from google.genai import types

# === CONFIGURATION ===
TARGET_WORDS = 2_000_000
WORDS_PER_TOPIC = 3500
DB_FILE = "infinity_state.json"

MACRO_DOMAINS = [
    "Engenharia Aeroespacial Avan√ßada", "Medicina Gen√¥mica", "Direito Internacional P√∫blico",
    "Arqueologia Proibida e Mist√©rios", "F√≠sica de Part√≠culas", "Filosofia da Mente",
    "Economia Comportamental", "Intelig√™ncia Artificial AGI", "Nanotecnologia Molecular",
    "Hist√≥ria da Guerra Fria", "Bot√¢nica e Farmacognosia", "Culin√°ria Molecular",
    "Engenharia de Materiais", "Criptografia Qu√¢ntica", "Psicologia Junguiana",
    "Oceanografia Abissal", "Teologia Comparada", "Arquitetura Sustent√°vel",
    "Geopol√≠tica do √Årtico", "Mitologia Sum√©ria e Babil√¥nica", "Biohacking e Longevidade",
    "Programa√ß√£o de Sistemas Operacionais", "Matem√°tica Topol√≥gica", "Virologia",
    "Astronomia de Ondas Gravitacionais"
]

class InfinityEngine:
    def __init__(self):
        self.store = CodexVectorStore()
        self.llm = GeminiClient()
        # FORCE GEMINI FLASH FOR HIGH SPEED & VOLUME
        self.llm.model = "gemini-2.0-flash-exp" 
        self.state = self._load_state()
        
    def _load_state(self):
        if os.path.exists(DB_FILE):
            try:
                with open(DB_FILE, 'r') as f:
                    return json.load(f)
            except:
                pass
        return {"total_words": 0, "topics_covered": []}

    def _save_state(self):
        with open(DB_FILE, 'w') as f:
            json.dump(self.state, f, indent=2)

    def generate_new_topics(self, macro_domain):
        """Asks Gemini to invent new specific topics."""
        prompt = f"""
        Atue como um Curador de Enciclop√©dia de N√≠vel PhD.
        Estamos construindo uma base de conhecimento sobre: {macro_domain}.
        
        T√≥picos J√Å COBERTOS (Evite estes): {json.dumps(self.state['topics_covered'][-20:])}
        
        Gere 3 sub-t√≥picos EXTREMAMENTE ESPEC√çFICOS, T√âCNICOS e AVAN√áADOS dentro de '{macro_domain}'.
        N√£o quero introdu√ß√µes. Quero "Deep Dives".
        ex: em vez de "Hist√≥ria de Roma", prefira "A Log√≠stica de Abastecimento das Legi√µes na G√°lia".
        
        Retorne APENAS uma lista Python de strings. Exemplo:
        ["T√≥pico A", "T√≥pico B", "T√≥pico C"]
        """
        
        try:
            response = self.llm.client.models.generate_content(
                model=self.llm.model,
                contents=prompt,
                config=types.GenerateContentConfig(temperature=0.7) # Higher temp for creativity
            )
            text = response.text.strip()
            # Cleanup Markdown stuff if present
            text = text.replace("```python", "").replace("```", "").strip()
            return eval(text) # Dangerous but effective for simple list parsing
        except Exception as e:
            print(f"‚ö†Ô∏è Erro gerando t√≥picos: {e}")
            return []

    def generate_content(self, topic):
        """Generates the masterclass content."""
        prompt = f"""
        Voc√™ √© a maior autoridade mundial em: {topic}.
        
        Escreva um Artigo T√©cnico/Cient√≠fico Completo (Masterclass) sobre isso.
        
        Estrutura Obrigat√≥ria:
        1. Fundamentos Te√≥ricos Profundos
        2. Complexidades T√©cnicas e Nuances
        3. Casos de Estudo ou Aplica√ß√µes Pr√°ticas
        4. Controv√©rsias ou Desafios Atuais
        5. Conclus√£o Prospectiva
        
        Estilo: Acad√™mico, Denso, Rico em Vocabul√°rio T√©cnico.
        M√≠nimo: 3000 palavras.
        """
        
        try:
            response = self.llm.client.models.generate_content(
                model=self.llm.model,
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.3, # Lower temp for accuracy
                    max_output_tokens=6000 # Max possible
                )
            )
            return response.text
        except Exception as e:
            print(f"‚ö†Ô∏è Erro gerando conte√∫do: {e}")
            return None

    def run(self):
        print("\n" + "‚ôæÔ∏è" * 40)
        print(f"   INFINITY ENGINE STARTED | TARGET: {TARGET_WORDS:,} WORDS")
        print("‚ôæÔ∏è" * 40 + "\n")
        
        while self.state['total_words'] < TARGET_WORDS:
            # 1. Pick a random domain
            domain = random.choice(MACRO_DOMAINS)
            print(f"üîç Explorando Dom√≠nio: {domain}")
            
            # 2. Invent sub-topics
            topics = self.generate_new_topics(domain)
            if not topics:
                continue
                
            print(f"   üí° Novos T√≥picos Descobertos: {topics}")
            
            # 3. Process each topic
            for topic in topics:
                if topic in self.state['topics_covered']:
                    print(f"   ‚è≠Ô∏è T√≥pico j√° existe: {topic}")
                    continue
                
                print(f"   ‚úçÔ∏è Escrevendo sobre: {topic}...")
                content = self.generate_content(topic)
                
                if content and len(content) > 1000:
                    # 4. Index
                    metadata = {
                        'source': 'INFINITY_ENGINE',
                        'macro_domain': domain,
                        'topic': topic,
                        'type': 'AUTONOMOUS_KNOWLEDGE'
                    }
                    ids = self.store.index_text(content, metadata)
                    
                    # Updates
                    word_count = len(content.split())
                    self.state['total_words'] += word_count
                    self.state['topics_covered'].append(topic)
                    self._save_state()
                    
                    print(f"   ‚úÖ Indexado! (+{word_count} palavras) | Total: {self.state['total_words']:,}")
                else:
                    print("   ‚ùå Conte√∫do falhou ou muito curto.")
                
                # Sleep to respect limits
                time.sleep(5)
            
            print(f"\nüìä Status: {self.state['total_words']:,} / {TARGET_WORDS:,} palavras")
            print("   üí§ Descansando 10s...\n")
            time.sleep(10)

if __name__ == "__main__":
    engine = InfinityEngine()
    engine.run()
